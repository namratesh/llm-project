{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTE9KUaKs4KS"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install diffusers transformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "hf_token = userdata.get('hf_token')\n",
        "login(hf_token, add_to_git_credential=True)"
      ],
      "metadata": {
        "id": "kcnvidEptCNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Genrator"
      ],
      "metadata": {
        "id": "nFf71UBItUOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "\n",
        "model_id = \"OFA-Sys/small-stable-diffusion-v0\"\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.enable_model_cpu_offload()\n",
        "\n",
        "\n",
        "prompt = \"A futuristic class full of students learning AI coding in the surreal style of Salvador Dali\"\n",
        "image = pipe(prompt).images[0]"
      ],
      "metadata": {
        "id": "bdvs7FhltKRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "\n",
        "# Display the image inline\n",
        "display(image)"
      ],
      "metadata": {
        "id": "CEUvanOTtVzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline\n"
      ],
      "metadata": {
        "id": "D-hmYxKqtn6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets diffusers"
      ],
      "metadata": {
        "id": "LkBFDd9oto2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "\n",
        "import torch\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "import soundfile as sf\n",
        "from IPython.display import Audio"
      ],
      "metadata": {
        "id": "VF8tNZj8t9Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# audio generator\n",
        "\n",
        "# Audio Generation\n",
        "\n",
        "synthesiser = pipeline(\"text-to-speech\", \"microsoft/speecht5_tts\", device='cuda')\n",
        "\n",
        "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
        "speaker_embedding = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n",
        "\n",
        "speech = synthesiser(\"Hi Good morning mastery!\", forward_params={\"speaker_embeddings\": speaker_embedding})\n",
        "\n",
        "sf.write(\"speech.wav\", speech[\"audio\"], samplerate=speech[\"sampling_rate\"])\n",
        "Audio(\"speech.wav\")"
      ],
      "metadata": {
        "id": "a32RuyZBt3hP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m-sXDS4PuG6Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}